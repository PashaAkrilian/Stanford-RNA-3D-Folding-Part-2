{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":118765,"databundleVersionId":15231210,"sourceType":"competition"},{"sourceId":14436239,"sourceType":"datasetVersion","datasetId":9221119}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Submission ","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# NOTEBOOK-3 / STAGE G â€” Build submission.csv (ONE CELL, Kaggle-SAFE)\n#\n# EN:\n# - Reads test_sequences.csv + sample_submission.csv from COMP_ROOT\n# - Reads final selection (Top-5) from RUN_DIR/final_selection/**/final_top5_test.parquet\n#   (or final_top5_val.parquet if test not available; will warn)\n# - For each test target:\n#     * loads coords for 5 candidates (npz with key \"coords\" or any (L,3))\n#     * if missing/unavailable -> uses safe fallback coords (line / helix-like placeholder)\n# - Writes /kaggle/working/submission.csv exactly in sample format\n#\n# ID:\n# - Ini akan selalu menghasilkan submission.csv yang valid formatnya.\n# - Kalau coords beneran belum ada (DRfold2/gemmi/ext belum aktif), file tetap jadi,\n#   tapi skor kompetisi tentu belum bagus. Begitu coords sudah ada, notebook ini otomatis pakai coords itu.\n# ============================================================\n\nimport os, json, math, hashlib, warnings\nfrom pathlib import Path\nfrom typing import Optional, Tuple, List, Dict\n\nimport numpy as np\nimport pandas as pd\n\nwarnings.filterwarnings(\"ignore\", category=pd.errors.DtypeWarning)\n\n# ----------------------------\n# 0) Paths\n# ----------------------------\nCOMP_ROOT = Path(\"/kaggle/input/stanford-rna-3d-folding-2\")\nif not COMP_ROOT.exists():\n    raise FileNotFoundError(\"Missing COMP_ROOT: /kaggle/input/stanford-rna-3d-folding-2\")\n\nTEST_SEQ_P = COMP_ROOT / \"test_sequences.csv\"\nSAMPLE_SUB_P = COMP_ROOT / \"sample_submission.csv\"\nif not TEST_SEQ_P.exists():\n    raise FileNotFoundError(f\"Missing: {TEST_SEQ_P}\")\nif not SAMPLE_SUB_P.exists():\n    raise FileNotFoundError(f\"Missing: {SAMPLE_SUB_P}\")\n\n# RUN_DIR detection (same as previous)\nif \"RUN_DIR\" in globals():\n    RUN_DIR = Path(RUN_DIR)\nelse:\n    base = Path(\"/kaggle/working/rna3d_run/candidates\")\n    if not base.exists():\n        raise FileNotFoundError(\"No /kaggle/working/rna3d_run/candidates. Set RUN_DIR or run earlier stages.\")\n    cfg_dirs = sorted([d for d in base.iterdir() if d.is_dir() and d.name.startswith(\"cfg_\")],\n                      key=lambda x: x.stat().st_mtime, reverse=True)\n    if not cfg_dirs:\n        raise FileNotFoundError(\"No cfg_* found. Set RUN_DIR or run earlier stages.\")\n    RUN_DIR = cfg_dirs[0]\n\nOUT_SUB = Path(\"/kaggle/working/submission.csv\")\n\nprint(\"=== SUBMISSION INPUTS ===\")\nprint(\"COMP_ROOT :\", COMP_ROOT)\nprint(\"RUN_DIR   :\", RUN_DIR)\nprint(\"TEST_SEQ  :\", TEST_SEQ_P)\nprint(\"SAMPLE_SUB:\", SAMPLE_SUB_P)\nprint(\"OUT_SUB   :\", OUT_SUB)\n\n# ----------------------------\n# 1) Utilities\n# ----------------------------\ndef stable_seed(s: str) -> int:\n    return int(hashlib.sha1(s.encode(\"utf-8\")).hexdigest()[:8], 16)\n\ndef load_npz_coords(npz_path: Path) -> Optional[np.ndarray]:\n    try:\n        z = np.load(npz_path, allow_pickle=False)\n        if \"coords\" in z:\n            c = np.asarray(z[\"coords\"])\n            if c.ndim == 2 and c.shape == (c.shape[0], 3) and np.isfinite(c).all():\n                return c\n        # fallback: any (L,3)\n        for k in z.files:\n            arr = np.asarray(z[k])\n            if arr.ndim == 2 and arr.shape[1] == 3 and np.isfinite(arr).all():\n                return arr\n        return None\n    except Exception:\n        return None\n\ndef clip_coords(c: np.ndarray, lo=-999.999, hi=9999.999) -> np.ndarray:\n    c = np.asarray(c, dtype=np.float64)\n    return np.clip(c, lo, hi)\n\ndef fallback_coords(L: int, seed: int = 0) -> np.ndarray:\n    \"\"\"\n    Deterministic placeholder geometry (NOT good for score, but valid).\n    Produces a gentle helix-ish curve scaled to Angstrom-like units.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    t = np.linspace(0, 1, L, dtype=np.float64)\n    # simple helix-like\n    x = 10.0 * np.cos(2 * np.pi * t) + 0.2 * rng.standard_normal(L)\n    y = 10.0 * np.sin(2 * np.pi * t) + 0.2 * rng.standard_normal(L)\n    z = 3.4 * np.arange(L, dtype=np.float64)  # ~base step scale\n    c = np.stack([x, y, z], axis=1)\n    return c\n\ndef get_latest_final_dir(run_dir: Path) -> Path:\n    base = run_dir / \"final_selection\"\n    if not base.exists():\n        return Path(\"\")\n    ds = [d for d in base.iterdir() if d.is_dir() and (d.name.startswith(\"final_\") or d.name.startswith(\"final\"))]\n    if not ds:\n        return Path(\"\")\n    ds.sort(key=lambda x: x.stat().st_mtime, reverse=True)\n    return ds[0]\n\n# ----------------------------\n# 2) Load test sequences + sample submission\n# ----------------------------\ndf_test_seq = pd.read_csv(TEST_SEQ_P)\ndf_samp = pd.read_csv(SAMPLE_SUB_P)\n\nif \"target_id\" not in df_test_seq.columns or \"sequence\" not in df_test_seq.columns:\n    raise ValueError(\"test_sequences.csv must contain columns: target_id, sequence\")\n\n# sample submission schema checks\nreq_cols = [\"ID\", \"resname\", \"resid\"]\nfor c in req_cols:\n    if c not in df_samp.columns:\n        raise ValueError(f\"sample_submission missing column: {c}\")\n\n# coordinate columns must be 15 (x_1..z_5)\ncoord_cols = [c for c in df_samp.columns if c.startswith((\"x_\",\"y_\",\"z_\"))]\nif len(coord_cols) != 15:\n    raise ValueError(f\"Expected 15 coord cols in sample_submission, got {len(coord_cols)}\")\n\n# ensure order x_1,y_1,z_1,...,x_5,y_5,z_5\ncoord_cols_sorted = []\nfor k in range(1, 6):\n    coord_cols_sorted += [f\"x_{k}\", f\"y_{k}\", f\"z_{k}\"]\nfor c in coord_cols_sorted:\n    if c not in df_samp.columns:\n        raise ValueError(f\"sample_submission missing coord col: {c}\")\n\n# ----------------------------\n# 3) Load final selection (Top-5 for test)\n# ----------------------------\nFINAL_DIR = get_latest_final_dir(RUN_DIR)\nif not FINAL_DIR:\n    raise FileNotFoundError(f\"Could not find RUN_DIR/final_selection/*. Run Stage F first. RUN_DIR={RUN_DIR}\")\n\np_test = FINAL_DIR / \"final_top5_test.parquet\"\np_val  = FINAL_DIR / \"final_top5_val.parquet\"\n\nif p_test.exists():\n    df_top5 = pd.read_parquet(p_test)\n    split_used = \"test\"\nelif p_val.exists():\n    df_top5 = pd.read_parquet(p_val)\n    split_used = \"val\"\n    print(\"[WARN] final_top5_test.parquet not found; using val selection as fallback for test submission.\")\nelse:\n    raise FileNotFoundError(f\"Missing final_top5_test.parquet (and no val fallback) in {FINAL_DIR}\")\n\n# required columns\nneed_cols = [\"target_id\", \"final_rank\", \"coords_path_used\"]\nfor c in need_cols:\n    if c not in df_top5.columns:\n        raise ValueError(f\"final_top5 file missing column: {c}\")\n\ndf_top5[\"target_id\"] = df_top5[\"target_id\"].astype(\"string\")\ndf_top5[\"final_rank\"] = pd.to_numeric(df_top5[\"final_rank\"], errors=\"coerce\").fillna(999).astype(\"int32\")\ndf_top5[\"coords_path_used\"] = df_top5[\"coords_path_used\"].fillna(\"\").astype(\"string\")\n\n# keep only ranks 1..5\ndf_top5 = df_top5[(df_top5[\"final_rank\"] >= 1) & (df_top5[\"final_rank\"] <= 5)].copy()\n\n# map target -> rank -> path\ntop5_map: Dict[str, Dict[int, str]] = {}\nfor r in df_top5.itertuples(index=False):\n    tid = str(r.target_id)\n    rk = int(r.final_rank)\n    p  = str(r.coords_path_used)\n    top5_map.setdefault(tid, {})[rk] = p\n\nprint(\"=== FINAL SELECTION LOADED ===\")\nprint(\"FINAL_DIR :\", FINAL_DIR)\nprint(\"split_used:\", split_used)\nprint(\"n_rows    :\", len(df_top5))\nprint(\"n_targets :\", len(top5_map))\n\n# ----------------------------\n# 4) Build submission rows following sample_submission IDs\n# ----------------------------\n# sample_submission has ID like \"R1107_1\" where prefix is target_id and suffix is resid.\n# We'll parse it and fill coords for 5 models.\n\ndef parse_sample_id(id_str: str) -> Tuple[str, int]:\n    # split on last \"_\" for safety\n    s = str(id_str)\n    if \"_\" not in s:\n        return s, 0\n    a, b = s.rsplit(\"_\", 1)\n    try:\n        return a, int(b)\n    except Exception:\n        return a, 0\n\n# Preload test sequences for L + resname per target (sequence gives resname)\nseq_map = dict(zip(df_test_seq[\"target_id\"].astype(\"string\"), df_test_seq[\"sequence\"].astype(str)))\n\n# Cache loaded coords per (target, rank)\ncoords_cache: Dict[Tuple[str, int], np.ndarray] = {}\n\ndef get_coords_for_target_rank(tid: str, rank: int) -> np.ndarray:\n    key = (tid, rank)\n    if key in coords_cache:\n        return coords_cache[key]\n    seq = seq_map.get(tid, \"\")\n    L = len(seq)\n    p = top5_map.get(tid, {}).get(rank, \"\")\n    coords = None\n    if p and Path(p).exists():\n        coords = load_npz_coords(Path(p))\n    if coords is None:\n        coords = fallback_coords(L, seed=stable_seed(f\"{tid}|{rank}\"))\n    # ensure length matches L (truncate/pad)\n    coords = np.asarray(coords, dtype=np.float64)\n    if coords.shape[0] != L:\n        if coords.shape[0] > L:\n            coords = coords[:L]\n        else:\n            pad = fallback_coords(L - coords.shape[0], seed=stable_seed(f\"{tid}|{rank}|pad\"))\n            coords = np.concatenate([coords, pad], axis=0)\n    coords = clip_coords(coords)\n    coords_cache[key] = coords\n    return coords\n\n# Build output dataframe by copying sample template to ensure exact columns/order\ndf_out = df_samp.copy()\n\n# Fill resname (from sequence) just to be safe (sample already has)\n# NOTE: sample has resname/resid; we won't break it.\n\n# Fill coords columns\nn_missing_targets = 0\ntargets_seen = set()\n\nfor i in range(len(df_out)):\n    tid, resid = parse_sample_id(df_out.at[i, \"ID\"])\n    tid = str(tid)\n    targets_seen.add(tid)\n\n    seq = seq_map.get(tid, None)\n    if seq is None:\n        # unknown target id in sample (shouldn't happen)\n        n_missing_targets += 1\n        continue\n\n    # 1-based resid -> index 0-based\n    idx = int(resid) - 1\n    if idx < 0 or idx >= len(seq):\n        # out of range, keep zeros\n        continue\n\n    # set resname from sequence for safety\n    df_out.at[i, \"resname\"] = seq[idx]\n    df_out.at[i, \"resid\"] = int(resid)\n\n    for k in range(1, 6):\n        c = get_coords_for_target_rank(tid, k)\n        x, y, z = c[idx, 0], c[idx, 1], c[idx, 2]\n        df_out.at[i, f\"x_{k}\"] = float(x)\n        df_out.at[i, f\"y_{k}\"] = float(y)\n        df_out.at[i, f\"z_{k}\"] = float(z)\n\n# final schema check\nexpected_cols = [\"ID\", \"resname\", \"resid\"] + coord_cols_sorted\ndf_out = df_out[expected_cols]\n\n# ensure numeric coords\nfor c in coord_cols_sorted:\n    df_out[c] = pd.to_numeric(df_out[c], errors=\"coerce\").fillna(0.0).astype(np.float64)\n\n# write\ndf_out.to_csv(OUT_SUB, index=False)\n\nprint(\"\\n[OK] submission.csv written:\", OUT_SUB)\nprint(\"rows:\", len(df_out), \"| targets_in_sample:\", len(targets_seen), \"| missing_targets_in_test_seq:\", n_missing_targets)\nprint(\"preview:\")\nprint(df_out.head(3).to_string(index=False))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}